
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Part 1: Generate Training Data üóÉÔ∏è üìù &#8212; Kaggle LLM Prompt Recovery</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Part 1 - Generate Training Data';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Part 2: Fine-Tuning ü§ó üî¢" href="Part%202%20-%20Fine-Tuning.html" />
    <link rel="prev" title="Prompt Recovery Competition" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Kaggle LLM Prompt Recovery - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Kaggle LLM Prompt Recovery - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Prompt Recovery Competition
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Part 1: Generate Training Data üóÉÔ∏è üìù</a></li>
<li class="toctree-l1"><a class="reference internal" href="Part%202%20-%20Fine-Tuning.html">Part 2: Fine-Tuning ü§ó üî¢</a></li>
<li class="toctree-l1"><a class="reference internal" href="Part%203%20-%20Evaluation.html">Part 3: Evaluation ‚úíÔ∏è üìë</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/alex-yang-upenn/kaggle-prompt-recovery" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/alex-yang-upenn/kaggle-prompt-recovery/issues/new?title=Issue%20on%20page%20%2FPart 1 - Generate Training Data.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Part 1 - Generate Training Data.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Part 1: Generate Training Data üóÉÔ∏è üìù</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-in-data">Loading in Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assembling-prompts">Assembling Prompts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-with-gemma">Inference with Gemma</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="part-1-generate-training-data">
<h1>Part 1: Generate Training Data üóÉÔ∏è üìù<a class="headerlink" href="#part-1-generate-training-data" title="Link to this heading">#</a></h1>
<p><em><strong>Full notebook contents viewable on <a class="reference external" href="https://www.kaggle.com/code/chuhuayang/prompt-recovery-pt-1-generate-training-data">Kaggle</a>.</strong></em></p>
<p>First, we need to generate some training data to tune the model with. Three components are necessary:</p>
<ol class="arabic simple">
<li><p>Original Texts - For best results, this should be a large and diverse set of paragraph-length texts</p></li>
<li><p>Rewrite Prompts</p></li>
<li><p>Re-written Text - Since the competition targets Gemma-7B, we will feed that model the first two components and obtain the output</p></li>
</ol>
<p>For Original Texts, since this is a Kaggle-hosted competition, we can take advantage of high quality natural language datasets available for free on Kaggle. To achieve diversity, we will use samples from four different well-curated datasets:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots">Wikipedia Movie Plots</a>: This dataset contains descriptions of thousands of movies from around the world. We can use the long-form plot summaries as Original Texts.</p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/datasets/nelgiriyewithana/emotions">Emotions</a>: This is a collection of English twitter messages, labeled with corresponding emotions. For our purposes, we can just use the tweets.</p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/datasets/dhruvildave/wikibooks-dataset">Wikibooks</a>: This is a massive dataset, containing the complete contents of the <a class="reference external" href="https://www.wikibooks.org/">Wikibooks</a> archives. We can use the <code class="docutils literal notranslate"><span class="pre">abstract</span></code> column from the English language table.</p></li>
</ul>
<p>For Rewrite Prompts, there are a variety of ways to obtain them. We can write them fully manually, or write <a class="reference external" href="https://www.madlibs.com/">Mad Libs</a>-style templates and write a simple program to fill in the blanks with different words. We can also prompt LLMs to generate them. These notebooks will use a Kaggle dataset containing a <a class="reference external" href="https://www.kaggle.com/datasets/chuhuayang/llm-prompt-recovery-competition">collection of prompts</a> generated by myself and others using these methods.</p>
<section id="loading-in-data">
<h2>Loading in Data<a class="headerlink" href="#loading-in-data" title="Link to this heading">#</a></h2>
<p>We will add the aforementioned datasets to our notebook, then read them in. We will perform two basic pre-processing steps to obtain more representative samples.</p>
<ul class="simple">
<li><p>For entries from Wikipedia Movie Plots and Wikibooks, because they can be very long, we will slice the text into chunks of 256 words, or tokens. This also helps save resources when performing training and inference.</p></li>
<li><p>Then, we will filter out entries that are too short or that contain sequences or characters not typical of English texts.</p></li>
</ul>
<p>In these notebooks, as an example, we will randomly select only a small subset of the available data to fine-tune on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sqlite3</span> <span class="k">as</span> <span class="nn">sql</span>

<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">256</span>
<span class="k">def</span> <span class="nf">create_slices</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">MAX_LENGTH</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">filtered_out</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;==&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">isascii</span><span class="p">())</span> 
    <span class="k">return</span> <span class="ow">not</span> <span class="n">filtered_out</span>

<span class="k">def</span> <span class="nf">preprocessing</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">processed_df</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">create_slices</span><span class="p">)</span>
    <span class="n">processed_df</span> <span class="o">=</span> <span class="n">processed_df</span><span class="o">.</span><span class="n">explode</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
    <span class="n">bool_df</span> <span class="o">=</span> <span class="n">processed_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">filter</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">processed_df</span><span class="p">[</span><span class="n">bool_df</span><span class="p">]</span>
    

<span class="n">series_1</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/kaggle/input/emotions/text.csv&quot;</span><span class="p">)[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="n">series_1</span> <span class="o">=</span> <span class="n">series_1</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df_1</span> <span class="o">=</span> <span class="n">series_1</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;original_text&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_1</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="n">series_2</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/kaggle/input/wikipedia-movie-plots/wiki_movie_plots_deduped.csv&quot;</span><span class="p">)[</span><span class="s2">&quot;Plot&quot;</span><span class="p">])</span>
<span class="n">series_2</span> <span class="o">=</span> <span class="n">series_2</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df_2</span> <span class="o">=</span> <span class="n">series_2</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;original_text&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_2</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="n">conn</span> <span class="o">=</span> <span class="n">sql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;/kaggle/input/wikibooks-dataset/wikibooks.sqlite&quot;</span><span class="p">)</span>

<span class="n">series_3</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_sql_query</span><span class="p">(</span><span class="s2">&quot;SELECT abstract FROM en&quot;</span><span class="p">,</span> <span class="n">conn</span><span class="p">)[</span><span class="s2">&quot;abstract&quot;</span><span class="p">])</span>
<span class="n">series_3</span> <span class="o">=</span> <span class="n">series_3</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df_3</span> <span class="o">=</span> <span class="n">series_3</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;original_text&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_3</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_14/3661208475.py:1: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                            original_text
48979   i feel positive about my k at the end of the m...
176784  i am feeling generous i can put up files fille...
148564  i have a feeling the defense is going to come ...
136809  i woke up in my bed alone for the last time fe...
261174  i am actually liking sofia and i feel this is ...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                           original_text
8524   the problem now which Playboy shows Bugs a fly...
11031  Singing-and-dancing stage star Julie (Betty Gr...
53471  school for admission where she meets George af...
55971  Dollar (played by Pawan Kumar (of Lucia (2013 ...
67650  When the Japan Coast Guard investigates an aba...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                           original_text
83536  Punjab was divided between the nations of Indi...
62306  Methodology: A body of practices, procedures, ...
16513  A computer-aided translation tool, developed b...
70892  The cause of mental disorders is usually unkno...
84067  This quest allows players access to a secret p...
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_1</span><span class="p">,</span> <span class="n">df_2</span><span class="p">,</span> <span class="n">df_3</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5000
</pre></div>
</div>
</div>
</div>
</section>
<section id="assembling-prompts">
<h2>Assembling Prompts<a class="headerlink" href="#assembling-prompts" title="Link to this heading">#</a></h2>
<p>Now, we will add the dataset containing example rewrite prompts to the notebook. Each chunk of text will be randomly matched up with one of the rewrite prompts. Then, we will place both components into a simple template, to get more consistent results from Gemma.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;rewrite_prompt&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/kaggle/input/prompt-recovery-sample-rewrite-prompts/prompts.csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;rewrite_prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>original_text</th>
      <th>rewrite_prompt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>i kinda thought that they might be giving some...</td>
      <td>Convey the same message as this text but throu...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>im being honest ive been feeling quite bitchy ...</td>
      <td>Rewrite this text in the style of a formal dip...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>i am trying to feel calmer and more relaxed ev...</td>
      <td>Imagine this as a conversation between quirky ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>i was called and invited to have a talk about ...</td>
      <td>Craft a version of the paragraph suitable for ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>off to do the same. After overcoming many chal...</td>
      <td>Elevate this text by introducing a compelling ...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Instruction:</span>
<span class="si">{rewrite_prompt}</span>

<span class="s2">Original Text:</span>
<span class="si">{original_text}</span>

<span class="s2">Response:</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rewrite_prompt</span><span class="o">=</span><span class="n">row</span><span class="o">.</span><span class="n">rewrite_prompt</span><span class="p">,</span> 
                                                             <span class="n">original_text</span><span class="o">=</span><span class="n">row</span><span class="o">.</span><span class="n">original_text</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference-with-gemma">
<h2>Inference with Gemma<a class="headerlink" href="#inference-with-gemma" title="Link to this heading">#</a></h2>
<p>We are ready to run inference with Gemma and obtain the rewritten texts. Since Kaggle gives access to TPU accelerators, this notebook will showcase how to use TPUs to achieve significant increases in compute power. We will be using Keras with Jax backend. Jax has support for <a class="reference external" href="https://huggingface.co/docs/transformers/v4.15.0/en/parallelism">Model Parallelism</a> techniques, enabling sharding, or partitioning, of weight and embedding tensors across the 8 TPU cores and distributed computation. This effectively combines the 8 cores‚Äô compute power and memory capacities, significantly speeding up computation time for a single batch and allowing larger models to be fit into memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>tensorflow-cpu
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-U<span class="w"> </span>keras-nlp<span class="w"> </span>tensorflow-hub
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-U<span class="w"> </span>keras&gt;<span class="o">=</span><span class="m">3</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-U<span class="w"> </span>tensorflow-text
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">keras-nlp 0.8.1 requires keras-core, which is not installed.</span>
<span class=" -Color -Color-Red">tensorflow 2.15.0 requires keras&lt;2.16,&gt;=2.15.0, but you have keras 3.0.5 which is incompatible.</span>
<span class=" -Color -Color-Red">tensorflow 2.15.0 requires ml-dtypes~=0.2.0, but you have ml-dtypes 0.3.2 which is incompatible.</span>
<span class=" -Color -Color-Red">tensorflow 2.15.0 requires tensorboard&lt;2.16,&gt;=2.15, but you have tensorboard 2.16.2 which is incompatible.</span>
<span class=" -Color -Color-Yellow">WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</span>

</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">23.0.1</span> -&gt; <span class=" -Color -Color-Green">24.0</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">pip install --upgrade pip</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">tensorflow-cpu 2.16.1 requires keras&gt;=3.0.0, but you have keras 2.15.0 which is incompatible.</span>
<span class=" -Color -Color-Red">tensorflow-cpu 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.</span>
<span class=" -Color -Color-Red">tensorflow-cpu 2.16.1 requires tensorboard&lt;2.17,&gt;=2.16, but you have tensorboard 2.15.2 which is incompatible.</span>
<span class=" -Color -Color-Yellow">WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</span>

<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">23.0.1</span> -&gt; <span class=" -Color -Color-Green">24.0</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">pip install --upgrade pip</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">tensorflow 2.15.0 requires keras&lt;2.16,&gt;=2.15.0, but you have keras 3.3.3 which is incompatible.</span>
<span class=" -Color -Color-Red">tensorflow-cpu 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.</span>
<span class=" -Color -Color-Red">tensorflow-cpu 2.16.1 requires tensorboard&lt;2.17,&gt;=2.16, but you have tensorboard 2.15.2 which is incompatible.</span>
<span class=" -Color -Color-Yellow">WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</span>

<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">23.0.1</span> -&gt; <span class=" -Color -Color-Green">24.0</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">pip install --upgrade pip</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Yellow">WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</span>

</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">23.0.1</span> -&gt; <span class=" -Color -Color-Green">24.0</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">pip install --upgrade pip</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>

<span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>E0525 04:26:30.349712299     121 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:&quot;2024-05-25T04:26:30.349696576+00:00&quot;, grpc_status:2}
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),
 TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),
 TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),
 TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),
 TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),
 TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),
 TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),
 TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]
</pre></div>
</div>
</div>
</div>
<p>We define <code class="docutils literal notranslate"><span class="pre">device_mesh</span></code> and <code class="docutils literal notranslate"><span class="pre">layout_map</span></code> configurations that describe how Gemma‚Äôs tensors should be sharded. Then, using the <strong><code class="docutils literal notranslate"><span class="pre">keras.distribution</span></code></strong> API, we pass these configurations to the Jax backend, which the performs the sharding when the model weights are loaded.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KERAS_BACKEND&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;jax&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;XLA_PYTHON_CLIENT_MEM_FRACTION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0.9&quot;</span> <span class="c1"># Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation</span>

<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">keras_nlp</span>

<span class="c1"># Create a device mesh with (1, 8) shape so that the weights are sharded across all 8 TPU cores.</span>
<span class="n">device_mesh</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">DeviceMesh</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="p">[</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">],</span>
    <span class="n">devices</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">list_devices</span><span class="p">())</span>

<span class="c1"># Create a layout map and define how each layer&#39;s weights should be sharded</span>
<span class="n">layout_map</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">LayoutMap</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
<span class="n">model_dim</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span>
<span class="c1"># Weights that match &#39;token_embedding/embeddings&#39; will be sharded on 8 TPUs</span>
<span class="n">layout_map</span><span class="p">[</span><span class="s2">&quot;token_embedding/embeddings&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_dim</span><span class="p">)</span>
<span class="c1"># Use a regex to match against the query, key and value matrices in the decoder attention layers</span>
<span class="n">layout_map</span><span class="p">[</span><span class="s2">&quot;decoder_block.*attention.*(query|key|value).*kernel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_dim</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="c1"># Shards the attention output, feed-forward gating, and feed-forward linear layers of the decoder</span>
<span class="n">layout_map</span><span class="p">[</span><span class="s2">&quot;decoder_block.*attention_output.*kernel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">model_dim</span><span class="p">)</span>
<span class="n">layout_map</span><span class="p">[</span><span class="s2">&quot;decoder_block.*ffw_gating.*kernel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">model_dim</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">layout_map</span><span class="p">[</span><span class="s2">&quot;decoder_block.*ffw_linear.*kernel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_parallel</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">ModelParallel</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">layout_map</span><span class="p">,</span> <span class="n">batch_dim_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span>

<span class="n">keras</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">set_distribution</span><span class="p">(</span><span class="n">model_parallel</span><span class="p">)</span>
<span class="n">gemma_lm</span> <span class="o">=</span> <span class="n">keras_nlp</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GemmaCausalLM</span><span class="o">.</span><span class="n">from_preset</span><span class="p">(</span><span class="s2">&quot;gemma_instruct_7b_en&quot;</span><span class="p">)</span>

<span class="c1"># Print out information on one decoder block to verify weights were sharded correctly</span>
<span class="n">decoder_block_1</span> <span class="o">=</span> <span class="n">gemma_lm</span><span class="o">.</span><span class="n">backbone</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s1">&#39;decoder_block_1&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">decoder_block_1</span><span class="p">))</span>
<span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">decoder_block_1</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">variable</span><span class="o">.</span><span class="n">path</span><span class="si">:</span><span class="s1">&lt;58</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">variable</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">:</span><span class="s1">&lt;16</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">variable</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">spec</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;metadata.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;metadata.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;task.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;config.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;metadata.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;metadata.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;config.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;config.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;model.weights.h5&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;metadata.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;metadata.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;preprocessor.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;tokenizer.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;tokenizer.json&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Attaching &#39;assets/tokenizer/vocabulary.spm&#39; from model &#39;keras/gemma/keras/gemma_instruct_7b_en/2&#39; to your Kaggle notebook...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;keras_nlp.src.models.gemma.gemma_decoder_block.GemmaDecoderBlock&#39;&gt;
decoder_block_1/pre_attention_norm/scale                    (3072,)           PartitionSpec(None,)
decoder_block_1/attention/query/kernel                      (16, 3072, 256)   PartitionSpec(None, &#39;model&#39;, None)
decoder_block_1/attention/key/kernel                        (16, 3072, 256)   PartitionSpec(None, &#39;model&#39;, None)
decoder_block_1/attention/value/kernel                      (16, 3072, 256)   PartitionSpec(None, &#39;model&#39;, None)
decoder_block_1/attention/attention_output/kernel           (16, 256, 3072)   PartitionSpec(None, None, &#39;model&#39;)
decoder_block_1/pre_ffw_norm/scale                          (3072,)           PartitionSpec(None,)
decoder_block_1/ffw_gating/kernel                           (3072, 24576)     PartitionSpec(&#39;model&#39;, None)
decoder_block_1/ffw_gating_2/kernel                         (3072, 24576)     PartitionSpec(&#39;model&#39;, None)
decoder_block_1/ffw_linear/kernel                           (24576, 3072)     PartitionSpec(None, &#39;model&#39;)
</pre></div>
</div>
</div>
</div>
<p>We will also cut Gemma‚Äôs response off at 512 tokens, to prevent excessively long responses to certain prompts and conserve compute resources.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">gemma_lm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">prompt</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="c1"># Gemma&#39;s responses will repeat the entire user prompt. We remove this unnecessary repetition</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;rewritten_text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">generate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/kaggle/working/training_data.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Prompt Recovery Competition</p>
      </div>
    </a>
    <a class="right-next"
       href="Part%202%20-%20Fine-Tuning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Part 2: Fine-Tuning ü§ó üî¢</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-in-data">Loading in Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assembling-prompts">Assembling Prompts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-with-gemma">Inference with Gemma</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chuhua Yang (Alex)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
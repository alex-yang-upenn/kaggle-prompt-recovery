{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ead5524",
   "metadata": {
    "papermill": {
     "duration": 0.004895,
     "end_time": "2024-05-26T07:46:46.702465",
     "exception": false,
     "start_time": "2024-05-26T07:46:46.697570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Fine-Tuning ðŸ¤— ðŸ”¢\n",
    "\n",
    "***Full notebook contents viewable on [Kaggle](https://www.kaggle.com/code/chuhuayang/prompt-recovery-pt-2-fine-tuning).***\n",
    "\n",
    "Previously, we generated a set of training data. Now, we will use this data to fine-tune our model for better performance on the prompt recovery task. We will utilize the powerful [HuggingFace Transformers API](https://huggingface.co/docs/transformers/index)  and its various integrations, which together provide a comprehensive collection of LLM training techniques and allows us to easily save, serialize, and deploy fine-tuned models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a47b8d",
   "metadata": {
    "papermill": {
     "duration": 0.005251,
     "end_time": "2024-05-26T07:46:46.713022",
     "exception": false,
     "start_time": "2024-05-26T07:46:46.707771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set-up\n",
    "\n",
    "Kaggle's environments does not currently come pre-loaded with all the libraries from the Hugging Face ecosystem, so we will start by installing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b78d31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:46:46.725561Z",
     "iopub.status.busy": "2024-05-26T07:46:46.724842Z",
     "iopub.status.idle": "2024-05-26T07:48:48.575150Z",
     "shell.execute_reply": "2024-05-26T07:48:48.574237Z"
    },
    "papermill": {
     "duration": 121.859471,
     "end_time": "2024-05-26T07:48:48.577791",
     "exception": false,
     "start_time": "2024-05-26T07:46:46.718320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 07:48:38.671776: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-26 07:48:38.671878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-26 07:48:38.841896: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -q -U transformers\n",
    "!pip install -q -U accelerate\n",
    "!pip install -q -U bitsandbytes\n",
    "%pip uninstall -y -q datasets \n",
    "%pip install -q datasets==2.16.0\n",
    "!pip install -q -U trl\n",
    "!pip install -q -U peft\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a61b79",
   "metadata": {
    "papermill": {
     "duration": 0.006103,
     "end_time": "2024-05-26T07:48:48.591352",
     "exception": false,
     "start_time": "2024-05-26T07:48:48.585249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the Model\n",
    "\n",
    "We load the model and tokenizer using the Transformers library. [bitsandbytes](https://huggingface.co/docs/bitsandbytes/main/en/index) is a library integrated with Transformers that allows quantization of LLMs in PyTorch to 8 or 4-bit. We create a bitsandbytes configuration and pass it to Transformers API when loading Gemma This significantly reduces the memory needed to run LLM inference. It also enables efficient LLM training techniques such as QLoRA, which we will be using.\n",
    "\n",
    "Here is a simple run-through of the parameters. Further explanations can be found in these articles: [Introduction](https://huggingface.co/blog/hf-bitsandbytes-integration), [4-bit Quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes)\n",
    "- `load_in_4bit`: bitsandbytes supports FP4 precision, a further reduction of model size from 8-bit quantizations\n",
    "- `bnb_4bit_use_double_quant`: This option saves even more memory by quantizing the scaling factors as well\n",
    "- `bnb_4bit_quant_type`: We have a choice between nf4 and fp4 datatypes. The QLoRA paper recommends nf4.\n",
    "- `bnb_4bit_compute_dtype`: When the 4-bit weights are unpacked, they will be scaled to this datatype. We use [bfloat16](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus), a datatype optimized for deep learning\n",
    "\n",
    "We set some additional configurations to optimize the training process\n",
    "- `config.use_cache`: Caching is unnecessary during fine-tuning. Disabling this saves memory.\n",
    "- `config.pretraining_tp = 1`: Disables tensor parallelism to avoid unexpected errors\n",
    "- `gradient_checkpointing_enable()`: Applies the [gradient checkpointing](https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-checkpointing) strategy during the backward pass, reducing memory usage at the cost of longer compute time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2250831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:48:48.606469Z",
     "iopub.status.busy": "2024-05-26T07:48:48.605116Z",
     "iopub.status.idle": "2024-05-26T07:52:01.301870Z",
     "shell.execute_reply": "2024-05-26T07:52:01.300849Z"
    },
    "papermill": {
     "duration": 192.706569,
     "end_time": "2024-05-26T07:52:01.304163",
     "exception": false,
     "start_time": "2024-05-26T07:48:48.597594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceecdc82b9c148158fbd3e374777c28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/kaggle/input/gemma/transformers/7b-it/3\",\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\")\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.add_eos_token = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eca802",
   "metadata": {
    "papermill": {
     "duration": 0.005593,
     "end_time": "2024-05-26T07:52:01.315643",
     "exception": false,
     "start_time": "2024-05-26T07:52:01.310050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the Data\n",
    "\n",
    "To aid the LLM in learning, we will standardize inputs using a template with labels and an instruction set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14cf9949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:52:01.328307Z",
     "iopub.status.busy": "2024-05-26T07:52:01.327680Z",
     "iopub.status.idle": "2024-05-26T07:52:01.333223Z",
     "shell.execute_reply": "2024-05-26T07:52:01.332442Z"
    },
    "papermill": {
     "duration": 0.013882,
     "end_time": "2024-05-26T07:52:01.335123",
     "exception": false,
     "start_time": "2024-05-26T07:52:01.321241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"### Instruction:\n",
    "Below, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the \"Original Text\" and \"Rewritten Text\", and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n",
    "\n",
    "### Original Text: \n",
    "{original_text}\n",
    "\n",
    "### Rewritten Text:\n",
    "{rewritten_text}\n",
    "\n",
    "### Response:\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_prompt(row):\n",
    "    return TEMPLATE.format(original_text=row[\"original_text\"],\n",
    "                           rewritten_text=row[\"rewritten_text\"],\n",
    "                           prompt=row[\"rewrite_prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f504a16",
   "metadata": {
    "papermill": {
     "duration": 0.005398,
     "end_time": "2024-05-26T07:52:01.346170",
     "exception": false,
     "start_time": "2024-05-26T07:52:01.340772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create train, test, and evaluation splits. Hugging Face uses its own [Datasets](https://huggingface.co/docs/datasets/main/en/index) library. There is a simple function that converts Pandas Dataframes to Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2234579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:52:01.358414Z",
     "iopub.status.busy": "2024-05-26T07:52:01.358136Z",
     "iopub.status.idle": "2024-05-26T07:52:01.771093Z",
     "shell.execute_reply": "2024-05-26T07:52:01.770116Z"
    },
    "papermill": {
     "duration": 0.421739,
     "end_time": "2024-05-26T07:52:01.773440",
     "exception": false,
     "start_time": "2024-05-26T07:52:01.351701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Below, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the \"Original Text\" and \"Rewritten Text\", and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n",
      "\n",
      "### Original Text: \n",
      "i have the feeling that ladislaus is not too keen on visitors at his place\n",
      "\n",
      "### Rewritten Text:\n",
      "Sure, here is the text rewritten through the eyes of an aspiring poet:\n",
      "\n",
      "In the halls of whispers and secrets,\n",
      "Ladislaus's abode, a sanctuary of dreams,\n",
      "Yet a veil of caution hangs thick in the air,\n",
      "For visitors, a burden he does not care.\n",
      "\n",
      "The poet's heart, a canvas of longing,\n",
      "Paints a picture of a heart that is torn,\n",
      "Between the desire to share his soul and the fear of intrusion,\n",
      "Ladislaus's stance, a reflection of his mood.\n",
      "\n",
      "### Response:\n",
      "Convey the same message as this text but through the eyes of an aspiring poet.\n",
      "\n",
      "### Instruction:\n",
      "Below, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the \"Original Text\" and \"Rewritten Text\", and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\n",
      "\n",
      "### Original Text: \n",
      "i am always ready to share my daily miseries with the world wide web and that is not about to change but having a day that left me feeling as defeated as yesterday has made today feel like a breeze\n",
      "\n",
      "### Rewritten Text:\n",
      "Sure, here is the text rewritten as a comedic script line:\n",
      "\n",
      "\"Oh boy, I'm ready to unload my daily dose of misery onto the intergalactic web, and you know what? That ain't changing. But let me tell you, having a day that made me feel as defeated as yesterday has made today feel like a breeze. I'm talking cosmic cocktails and existential dread, baby!\"\n",
      "\n",
      "Please note that I have added some comedic flair and exaggerated the language for comedic effect.\n",
      "\n",
      "### Response:\n",
      "Imagine the text as a line from a comedic script for an intergalactic sitcom.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/prompt-recovery-pt-1-generate-training/training_data.csv\")\n",
    "\n",
    "df_train = df[0:4200].copy().reset_index()\n",
    "df_eval = df[4200:4400].copy().reset_index()\n",
    "\n",
    "df_train[\"text\"] = df_train.apply(generate_prompt, axis=1)\n",
    "df_eval[\"text\"] = df_eval.apply(generate_prompt, axis=1)\n",
    "\n",
    "print(random.choice(df_train[\"text\"]))\n",
    "print(random.choice(df_eval[\"text\"]))\n",
    "\n",
    "train_data = Dataset.from_pandas(df_train)\n",
    "eval_data = Dataset.from_pandas(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d38883",
   "metadata": {
    "papermill": {
     "duration": 0.006576,
     "end_time": "2024-05-26T07:52:01.786612",
     "exception": false,
     "start_time": "2024-05-26T07:52:01.780036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Configurations\n",
    "\n",
    "The [PEFT](https://huggingface.co/docs/peft/index) library, which we imported earlier, integrates seamlessly with other Hugging Face libraries like Trainer, bitsandbytes, and Accelerate.\n",
    "\n",
    "We create a PEFT-enabled model. Here is a quick run-through of the LoRA hyperparameters. We will mostly follow the numbers used in the [QLoRA paper's](https://arxiv.org/abs/2305.14314) chatbot training:\n",
    "- `r`: The rank of the LoRA matrix being injected into the model. A larger number means more trainable parameters.\n",
    "- `lora_alpha`: Controls how much influence the LoRA weights have over model behavior. A larger number means more influence, and vice versa.\n",
    "- `lora_dropout`: Dropout is a common technique where randomly selected neurons are ignored during training, 0.1 means a 10% probability.\n",
    "- `target_modules`: Controls which modules LoRA will be applied to. We target all linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fa6cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:52:01.801643Z",
     "iopub.status.busy": "2024-05-26T07:52:01.801288Z",
     "iopub.status.idle": "2024-05-26T07:52:04.693146Z",
     "shell.execute_reply": "2024-05-26T07:52:04.692178Z"
    },
    "papermill": {
     "duration": 2.901844,
     "end_time": "2024-05-26T07:52:04.695245",
     "exception": false,
     "start_time": "2024-05-26T07:52:01.793401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 200,015,872 || all params: 8,737,696,768 || trainable%: 2.2891\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5631d8",
   "metadata": {
    "papermill": {
     "duration": 0.006291,
     "end_time": "2024-05-26T07:52:04.707822",
     "exception": false,
     "start_time": "2024-05-26T07:52:04.701531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Preparing for training on the 2 T4 GPUs set-up that Kaggle offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac4ff4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:52:04.721532Z",
     "iopub.status.busy": "2024-05-26T07:52:04.721221Z",
     "iopub.status.idle": "2024-05-26T07:52:05.015850Z",
     "shell.execute_reply": "2024-05-26T07:52:05.014868Z"
    },
    "papermill": {
     "duration": 0.304229,
     "end_time": "2024-05-26T07:52:05.018132",
     "exception": false,
     "start_time": "2024-05-26T07:52:04.713903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f0400",
   "metadata": {
    "papermill": {
     "duration": 0.006574,
     "end_time": "2024-05-26T07:52:05.031230",
     "exception": false,
     "start_time": "2024-05-26T07:52:05.024656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hugging Face's [TRL library](https://huggingface.co/docs/trl/en/index) offers a large array of tools for model training. We will be using the Supervised Fine-tuning Trainer. Here is a quick run-through of the arguments:\n",
    "- `save_steps` `save_total_limit` `load_best_model_at_end`: The Trainer saves checkpoints after every set number of steps. Our configuration will preserve the most recent checkpoint and the best checkpoint, and select the best checkpoint for use at the end of training.\n",
    "- `logging_steps` `report_to`: Logs training metrics after every set number of training steps. Integrated with tools such as [Weights & Biases](https://docs.wandb.ai/guides) and [Tensorboard](https://www.tensorflow.org/tensorboard) for visualization and analysis. For simplicity, this notebook will not utilize any of these additional platforms. \n",
    "- `eval_strategy` `eval_steps`: Enables evaluation after every set number of training steps.\n",
    "- `per_device_train_batch_size` `gradient_accumulation_steps`: Training batchsize and number of batches to [accumulate gradients](https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-accumulation) for. We set the former to 1 to minimize memory usage and use the latter to mimic the effects of batched samples.\n",
    "- `per_device_eval_batch_size` `eval_accumulation_steps`: Controls batchsize and number of batches to evaluate before moving results to CPU. We set both to 1 to minimize memory usage.\n",
    "- `learning_rate` `lr_scheduler_type`: Sets the learning rate and learning rate schedule. Values are those used by QLoRA paper.\n",
    "- `weight_decay`: Adds a penalty term for larger weights to prevent overfitting\n",
    "- `max_grad_norm`: Sets the threshold for gradient clipping. 0.3 is the value used by the QLoRA paper.\n",
    "- `fp16=True`: Enables training in half precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11107b1",
   "metadata": {
    "papermill": {
     "duration": 0.005881,
     "end_time": "2024-05-26T07:52:05.043296",
     "exception": false,
     "start_time": "2024-05-26T07:52:05.037415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We highlight two particularly important arguments\n",
    "- **`optim`**: We will use a special version of the Adam optimizer with weight decay, [paged_adamw_8bit](https://huggingface.co/docs/bitsandbytes/en/optimizers), offered by bitsandbytes. It is quantized to 8-bits, saving large amounts of memory and speeding up compute with no performance loss. Additionally, this optimizer leverages CUDA's Unified Memory feature, utilizing CPU memory when the GPU runs out of memory.\n",
    "\n",
    "- **`data_collator`**: Put simply, the [Data Collator](https://huggingface.co/docs/transformers/en/main_classes/data_collator) class forms batches from a Dataset, and applies processing. The data collator used here, `DataCollatorForCompletionOnlyLM` ensures that all tokens before the user-defined response template do not contribute to the gradient. The model is trained on only the generated rewrite prompts. `packing=False` prevents any conflicts with this data collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5e4fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:52:05.056649Z",
     "iopub.status.busy": "2024-05-26T07:52:05.056337Z",
     "iopub.status.idle": "2024-05-26T07:52:09.430171Z",
     "shell.execute_reply": "2024-05-26T07:52:09.429254Z"
    },
    "papermill": {
     "duration": 4.38282,
     "end_time": "2024-05-26T07:52:09.432141",
     "exception": false,
     "start_time": "2024-05-26T07:52:05.049321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433103a0aee941dbb62687ea292d49c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db11a39f95a4be8b755a8ad6a3a42b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./prompt-recovery-finetune\",\n",
    "    save_steps=15,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=15,\n",
    "    report_to=\"none\",\n",
    "    eval_strategy='steps',\n",
    "    eval_steps = 15,\n",
    "    num_train_epochs=1,\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    max_grad_norm=0.3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,   \n",
    ")\n",
    "\n",
    "response_template = \"### Response:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    dataset_text_field=\"text\",\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26594202",
   "metadata": {
    "papermill": {
     "duration": 0.006846,
     "end_time": "2024-05-26T07:52:09.446089",
     "exception": false,
     "start_time": "2024-05-26T07:52:09.439243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training and Saving\n",
    "\n",
    "`trainer.train()` abstracts away the complicated training and evaluation loops, as well as Accelerate integrations.\n",
    "\n",
    "Afterwards, instead of saving the entirety of the model's weights, PEFT saves an Adapter, a folder consisting of only the new LoRA weights and configurations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30993be2",
   "metadata": {
    "papermill": {
     "duration": 0.006633,
     "end_time": "2024-05-26T07:52:09.460423",
     "exception": false,
     "start_time": "2024-05-26T07:52:09.453790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ":::{tip}\n",
    "If the notebook crashes with errors such as `RuntimeError: CUDA error: an illegal memory access was encountered`, we can easily resume training from the latest checkpoint with the argument `resume_from_checkpoint=True`. Ensure all other arguments are the same, and ensure `output_dir` is in the same state as before the training was interrupted. On Kaggle, since `/kaggle/working` resets between notebook runs, create a dataset containing the `outputs_dir` folder add it as an input for the next run.\n",
    "\n",
    "```Python\n",
    "!cp -r /kaggle/input/checkpoints/prompt_recovery_finetune /kaggle/working/\n",
    "\n",
    "...\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84002303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T07:52:09.475459Z",
     "iopub.status.busy": "2024-05-26T07:52:09.474630Z",
     "iopub.status.idle": "2024-05-26T14:00:58.880908Z",
     "shell.execute_reply": "2024-05-26T14:00:58.880115Z"
    },
    "papermill": {
     "duration": 22129.416465,
     "end_time": "2024-05-26T14:00:58.883468",
     "exception": false,
     "start_time": "2024-05-26T07:52:09.467003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 6:08:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.647700</td>\n",
       "      <td>0.921029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.810100</td>\n",
       "      <td>0.693134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.589362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.555800</td>\n",
       "      <td>0.558700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.538900</td>\n",
       "      <td>0.526677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.439481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.429500</td>\n",
       "      <td>0.426885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.377671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.355361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.336657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.330116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.424100</td>\n",
       "      <td>0.304241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>0.275571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.281969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.253618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.259762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.274455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.244083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.230947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.239970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.196642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.227365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.220264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.212811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.213365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.196246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.189716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.209950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.190855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.176299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.173038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.161604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.146135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.158499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.161419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.model.save_pretrained(\"./adapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1acbbc2",
   "metadata": {
    "papermill": {
     "duration": 0.006898,
     "end_time": "2024-05-26T14:00:58.898176",
     "exception": false,
     "start_time": "2024-05-26T14:00:58.891278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results\n",
    "\n",
    "Adapters are a lightweight and flexible design. To load and run a trained QLoRA model, first load the base model like normal, using the same configurations. Then, use the PeftModel.from_pretrained() method, passing in the base model and the directory of the Adapter. \n",
    "\n",
    "```Python\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/kaggle/input/gemma/transformers/7b-it/3\",\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "base_model.gradient_checkpointing_enable()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "...\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"/kaggle/input/{dataset_name}/adapter\", adapter_name=\"adapter_0\", is_trainable=True)\n",
    "model.enable_input_require_grads()\n",
    "```\n",
    "This PeftModel can be used just like any normal model. We can perform inference using the `generate()` method. We can further finetune the Adapter by passing it into to a `SFTTrainer` set-up, just like above. This continues updating the LoRA weights of the Adapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa309c",
   "metadata": {
    "papermill": {
     "duration": 0.007031,
     "end_time": "2024-05-26T14:00:58.912337",
     "exception": false,
     "start_time": "2024-05-26T14:00:58.905306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "PeftModels can even juggle multiple Adapters. After the PeftModel is instantiated, add more adapters with the `load_adapters()` method.\n",
    "\n",
    "```Python\n",
    "model.load_adapter(\"/kaggle/input/{dataset_name}/{additional_adapter_1}\", adapter_name=\"adapter_1\")\n",
    "model.load_adapter(\"/kaggle/input/{dataset_name}/{additional_adapter_2}\", adapter_name=\"adapter_2\")\n",
    "...\n",
    "```\n",
    "\n",
    "Only one Adapter can be active at a time. The active Adapter is used when performing inference and further finetuning. We can set any of the loaded Adapters as the active Adapter. We can also disable all Adapters to return to the base model\n",
    "\n",
    "```Python\n",
    "model.set_adapter(\"adapter_1\")\n",
    "model.disable_adapter()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21283fff",
   "metadata": {
    "papermill": {
     "duration": 0.006902,
     "end_time": "2024-05-26T14:00:58.926258",
     "exception": false,
     "start_time": "2024-05-26T14:00:58.919356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, PEFT offers an algorithm for [merging Adapters](https://huggingface.co/docs/peft/en/developer_guides/model_merging), combining the abilities of separate Adapters into one. An introduction to the algorithm can be found [here](https://huggingface.co/blog/peft_merging).\n",
    "\n",
    "```Python\n",
    "adapters = [\"adapter_0\", \"adapter_1\", \"adapter_2\"]\n",
    "weights=[2.0, 1.0, 1.0]\n",
    "finetuned_model.add_weighted_adapter(adapters=adapters, weights=weights, adapter_name=\"merge\", combination_type=\"ties\", density=1.0)\n",
    "finetuned_model.set_adapter(\"merge\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 179635901,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 28808,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22458.987351,
   "end_time": "2024-05-26T14:01:02.803168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-26T07:46:43.815817",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0364df3bc5294b6f8ffcf1d2cd615c6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e6636295a7f4a04b882ff5503a43729",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_385c2a18ce934fa7a45fa2569cd0d6b8",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "0db11a39f95a4be8b755a8ad6a3a42b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e8c7beae3a3d4db9814dfe40b45b63a5",
        "IPY_MODEL_2c6cf255fc4048a8bf886b1ff3f85089",
        "IPY_MODEL_95b4922fa97c4f15923a49a82dec20d2"
       ],
       "layout": "IPY_MODEL_d14532d4a44a4e9a8de75559b22715ee"
      }
     },
     "16c15d7ba0774dd486c4a4e7b5a341bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "17edfe54f00040cab23a17bb87809089": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1bc3c36e2758424c8106c755fd9925f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1f99800ef83346fbaa2dd811760771ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a706350dc974f0091211a7a6beb98a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c7fad07c8e064382b4e8ad21a4111601",
       "max": 4200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_901157357949425ba62287a12ec93ccc",
       "value": 4200
      }
     },
     "2c6cf255fc4048a8bf886b1ff3f85089": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_587c0d9346414198875a9cf32fb9e0a2",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7afa0e34d7f64a248cf4eb8a177f2384",
       "value": 200
      }
     },
     "385c2a18ce934fa7a45fa2569cd0d6b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "433103a0aee941dbb62687ea292d49c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_49f6df7f21444c22a20371a5948ea63d",
        "IPY_MODEL_2a706350dc974f0091211a7a6beb98a7",
        "IPY_MODEL_aba1bd952be44a0eb875a020b96be3bc"
       ],
       "layout": "IPY_MODEL_b2c442f58267413fa175146ee124afa2"
      }
     },
     "498339bc6be1458bae98c291804fd152": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "49f6df7f21444c22a20371a5948ea63d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_53830819d2054665ab20a9d7990e4470",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_67c6a77b080a41ed8495a603be5c670b",
       "value": "Map: 100%"
      }
     },
     "4e6636295a7f4a04b882ff5503a43729": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53830819d2054665ab20a9d7990e4470": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "587c0d9346414198875a9cf32fb9e0a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67c6a77b080a41ed8495a603be5c670b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7afa0e34d7f64a248cf4eb8a177f2384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7b69fed51d604f2594a27a842faee659": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87839db44c2c43fdb76a3c7ea404e307": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "901157357949425ba62287a12ec93ccc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "95b4922fa97c4f15923a49a82dec20d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad3b92d19d5b40b68252795fc659ceb3",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9ba50a8e86ec42439929be71ddaa8ce9",
       "value": " 200/200 [00:00&lt;00:00, 1553.73 examples/s]"
      }
     },
     "9ba50a8e86ec42439929be71ddaa8ce9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aba1bd952be44a0eb875a020b96be3bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d590a3d6e27e4d4785d62bc11b4e4aff",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_1bc3c36e2758424c8106c755fd9925f8",
       "value": " 4200/4200 [00:02&lt;00:00, 1712.80 examples/s]"
      }
     },
     "aca544b8703d447d87774a73e0f1dc75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87839db44c2c43fdb76a3c7ea404e307",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_498339bc6be1458bae98c291804fd152",
       "value": 4
      }
     },
     "ad3b92d19d5b40b68252795fc659ceb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2c442f58267413fa175146ee124afa2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c6b6833476c24b28afa108c0ed004d7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e808b04f97814022817072320e34d423",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_16c15d7ba0774dd486c4a4e7b5a341bc",
       "value": " 4/4 [03:10&lt;00:00, 43.36s/it]"
      }
     },
     "c7fad07c8e064382b4e8ad21a4111601": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ceecdc82b9c148158fbd3e374777c28c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0364df3bc5294b6f8ffcf1d2cd615c6d",
        "IPY_MODEL_aca544b8703d447d87774a73e0f1dc75",
        "IPY_MODEL_c6b6833476c24b28afa108c0ed004d7b"
       ],
       "layout": "IPY_MODEL_1f99800ef83346fbaa2dd811760771ed"
      }
     },
     "d14532d4a44a4e9a8de75559b22715ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d590a3d6e27e4d4785d62bc11b4e4aff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e808b04f97814022817072320e34d423": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8c7beae3a3d4db9814dfe40b45b63a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7b69fed51d604f2594a27a842faee659",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_17edfe54f00040cab23a17bb87809089",
       "value": "Map: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
